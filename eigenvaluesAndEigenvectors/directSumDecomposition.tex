\documentclass{ximera}
\input{../preamble.tex}
\title{Direct sum decomposition}
\author{Crichton Ogle}

\begin{document}
\begin{abstract}
The subspace spanned by the eigenvectors of a matrix, or a linear transformation, can be expressed as a direct sum of eigenspaces. 
\end{abstract}
\maketitle

A vector space $V$ is a sum of subspaces $W_1$, $W_2$ - written as $V = W_1 + W_2$ - if every vector in ${\bf v}\in V$ can be written as ${\bf v} = {\bf w}_1 + {\bf w}_2$ with ${\bf w}_i\in W_i$ (that is $V = Span\{W_1, W_2\}$). The vector space $V$ is a {\it direct sum} of two subspaces $W_1, W_2$ if
\begin{itemize}
\item $V = W_1 + W_2$;
\item $W_1\cap W_2 = \{{\bf 0}\}$.
\end{itemize}

Another way of expressing this is to say that every vector in $V$ can be written {\it uniquely} as a sum of i) a vector in $W_1$ and ii) a vector in $W_2$. If $V$ is a direct sum of $W_1$ and $W_2$, we write $V = W_1\oplus W_2$. 
\vskip.2in


A similar description applies more generally to an $m$-fold direct sum: $V$ is a direct sum of subspaces $W_i$, $1\le i\le m$ if
\begin{itemize}
\item Every ${\bf v}\in V$ can be written as ${\bf v} = \sum_{i=1}^m{\bf w}_i$ for ${\bf w}_i\in W_i$;
\item $W_i\cap \left(\sum_{j\ne i} W_j\right) = \{{\bf 0}\}$.
\end{itemize}

\begin{proposition} $V = W_1\oplus W_2\oplus\dots\oplus W_n$ if and only if every vector ${\bf v}\in V$ can be expressed uniquely as ${\bf v} = \sum_{i=1}^n {\bf w}_i$ with ${\bf w}_i\in W_i$, $1\le i\le n$.
\end{proposition}

\begin{proof} Assume that $V = \sum_{i=1}^n W_i$. Suppose also that
\[
{\bf v} = {\bf w}_1 + \dots + {\bf w}_n = {\bf w}'_1 +\dots {\bf w}'_n
\]
where ${\bf w}_i, {\bf w}_i'\in W_i, 1\le i\le n$. If the representation is unique for all ${\bf v}\in V$ then the sum is a direct sum by definition. On the other hand, suppose ${\bf w}_i\ne {\bf w}_i'$ for some $i$. We can assume without loss of generality that $i=1$. Then
\[
0\ne {\bf w}_1 - {\bf w}_1' = \sum_{i=2}^n {\bf w}_i' - {\bf w}_i\in \sum_{i=2}^n W_i
\]
implying $W_1\cap\left(\sum_{i=2}^n W_i\right)\ne \{{\bf 0}\}$, so that the sum is not a direct sum.
\end{proof}

When $V$ is a direct sum of the subspaces $\{W_i\}$ we indicate this by writing either $V = \bigoplus_{i=1}^m W_i$, or $V = W_1\oplus W_2\oplus\dots \oplus W_m$. 

\begin{exercise} Show that if $\{{\bf u}_1,\dots, {\bf u}_m\}$ is a linearly independent set of vectors in $W_1$, $\{{\bf v}_1,\dots, {\bf v}_n\}$ a linearly independent set of vectors in $W_2$, and $W_i\subset V$ with $W_1\cap W_2 = \{{\bf 0}\}$, then $\{{\bf u}_1,\dots, {\bf u}_m,{\bf v}_1,\dots, {\bf v}_n\}$ is linearly independent.
\end{exercise}
\vskip.2in

\begin{exercise} Suppose $\{{\bf v}_1, {\bf v}_2,\dots,{\bf v}_n\}$ is a basis for $V$. Let
\[
W_1 = Span\{{\bf v}_1, {\bf v}_1,\dots,{\bf v}_k\},\qquad W_2 = Span\{{\bf v}_{k+1},{\bf v}_{k+2},\dots,{\bf v}_n\}
\]
Show that $V = W_1\oplus W_2$.
\end{exercise}

Define $E(A)\subset\mathbb R^n$ to be the supspace of $\mathbb R^n$ spanned by the eigenvectors of $A$ (this may or may not be all of $\mathbb R^n$). As we have seen, the number of distinct possible eigenvalues of $A$ is at most $n$ when $A$ is an $n\times n$ matrix. In particular, it is finite.

\begin{theorem} Given a real $n\times n$ matrix $A$, let $\lambda_1,\dots,\lambda_m$ be the distinct real eigenvalues of $A$. Then 
\[
E(A) = E_{\lambda_1}(A)\oplus E_{\lambda_2}(A)\oplus\dots\oplus E_{\lambda_m}(A)
\]
\end{theorem}

\begin{proof} For $m=1$ the statement is trivially true. So suppose that $m=2$, and ${\bf 0}\ne {\bf v}\in E_{\lambda_1}(A)\cap E_{\lambda_2}(A)$ with $\lambda_1\ne \lambda_2$. Then
\[
A*{\bf v} = \lambda_1{\bf v} = \lambda_2{\bf v}
\]
implying $(\lambda_1 - \lambda_2){\bf v} = {\bf 0}$. As $\lambda_1 - \lambda_2\ne 0$, this implies ${\bf v} = {\bf 0}$.
\vskip.2in

Inductively we can assume that the span of the union of the eigenspaces $\{E_{\lambda_i}(A)\}_{i=2}^m$ is the direct sum of these subspaces.  We wish to show that $E_{\lambda_1}(A)\cap (E_{\lambda_2}(A)\oplus\dots\oplus E_{\lambda_m}(A)) = {\bf 0}$. So let ${\bf v}_1\in E_{\lambda_1}(A)\cap \big(E_{\lambda_2}(A)\oplus\dots\oplus E_{\lambda_m}(A)\big)$. Then 
\[
{\bf v}_1 = {\bf v}_2 + {\bf v}_3 +\dots + {\bf v}_m
\]
where $A*{\bf v}_i = \lambda_i{\bf v}_i, 1\le i\le m$. Multiplying the above equality on the left by $A$ gives
\[
\lambda_1({\bf v}_2 + {\bf v}_3 +\dots + {\bf v}_m) = \lambda_1{\bf v}_1 = A*{\bf v}_1 = A*({\bf v}_2 + {\bf v}_3 +\dots + {\bf v}_m) = \lambda_2{\bf v}_2 + \lambda_3{\bf v}_3 +\dots + \lambda_m{\bf v}_m
\]
Subtracting gives
\[
(\lambda_1 - \lambda_2){\bf v}_2 + (\lambda_1 - \lambda_3){\bf v}_3 +\dots + (\lambda_1 - \lambda_m){\bf v}_m = {\bf 0}
\]
As the eigenvalues are distinct, the coefficient $(\lambda_1 - \lambda_i)$ is non-zero for each $2\le i\le m$. Then
\[
{\bf v}_2 = \left(\frac{-1}{(\lambda_1 - \lambda_2)}\right)\Big((\lambda_1 - \lambda_3){\bf v}_3 \dots + (\lambda_1 - \lambda_{i-1}){\bf v}_{i-1} + (\lambda_1 -\lambda_{i+1}){\bf v}_{i+1}\dots +(\lambda_1 - \lambda_m){\bf v}_m\Big)
\]
Induction allows us to assume
\[
E_{\lambda_2}(A)\cap\left(E_{\lambda_3}(A)\oplus E_{\lambda_4}(A)\oplus\dots\oplus E_{\lambda_{i-1}}(A)\oplus E_{\lambda_{i+1}}(A)\oplus\dots\oplus E_{\lambda_m}(A)\right) = {\bf 0}
\]
which together with the last equation implies ${\bf v}_i = {\bf 0}$ for all $2\le i\le m$. As ${\bf v}_1 = \sum_{i=2}^m {\bf v}_i$ we conclude finally that ${\bf v}_1 = {\bf 0}$. Since ${\bf v}_1$ was taken to be an arbitrary element of $E_{\lambda_1}(A)\cap (E_{\lambda_2}(A)\oplus\dots\oplus E_{\lambda_m}(A))$ this shows the intersection must be zero, completing the proof.
\end{proof}
\vskip.2in

More generally, let $L:V\to V$ be a linear self-map on $V$ (as before). Without appeal to bases, we write $E(L)$ for the linear span of the eigenvectors of $L$ in $V$. Then by exactly the same argument one has

\begin{theorem} If $\lambda_1,\dots,\lambda_m$ are the distinct real eigenvalues of $L$, then
\[
E(L) = E_{\lambda_1}(L)\oplus E_{\lambda_2}(L)\oplus\dots\oplus E_{\lambda_m}(L)
\]
\end{theorem}

In the case $E(L) = V$, this yields a direct sum decomposition of $V$ into eigenspaces of $L$, which is a very useful thing to know (in the cases it occurs). We will investigate this property in more detail next.
\vskip.3in

\end{document}
